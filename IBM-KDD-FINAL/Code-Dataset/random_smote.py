# -*- coding: utf-8 -*-
"""random_SMOTE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bCqkYCaXaURRQPt6ArKJM_2_5lerZK79

Importing the Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""Reading Datasets"""

train_df = pd.read_csv('KDDTrain+.csv')
test_df=pd.read_csv('KDDTest+.csv')

df=pd.concat([train_df,test_df]).drop_duplicates().reset_index(drop=True)

df

columns = (['duration'
,'protocol_type'
,'service'
,'flag'
,'src_bytes'
,'dst_bytes'
,'land'
,'wrong_fragment'
,'urgent'
,'hot'
,'num_failed_logins'
,'logged_in'
,'num_compromised'
,'root_shell'
,'su_attempted'
,'num_root'
,'num_file_creations'
,'num_shells'
,'num_access_files'
,'num_outbound_cmds'
,'is_host_login'
,'is_guest_login'
,'count'
,'srv_count'
,'serror_rate'
,'srv_serror_rate'
,'rerror_rate'
,'srv_rerror_rate'
,'same_srv_rate'
,'diff_srv_rate'
,'srv_diff_host_rate'
,'dst_host_count'
,'dst_host_srv_count'
,'dst_host_same_srv_rate'
,'dst_host_diff_srv_rate'
,'dst_host_same_src_port_rate'
,'dst_host_srv_diff_host_rate'
,'dst_host_serror_rate'
,'dst_host_srv_serror_rate'
,'dst_host_rerror_rate'
,'dst_host_srv_rerror_rate'
,'attack'
,'level'])

train_df.columns = columns
test_df.columns = columns
train_df

"""Preprocessing"""

print("No. of Null Values : ",train_df.isna().sum().sum())
duplicates = len(train_df[train_df.duplicated()])
print("The No. of Duplicates :  ",duplicates)

train_df.dtypes

train_df.nunique()

train_df.var()

train_df.drop(["num_outbound_cmds"],axis=1,inplace=True) ## since variance is  0 we are dropping that column
test_df.drop(["num_outbound_cmds"],axis=1,inplace=True) ## since variance is  0 we are dropping that column

"""Correlation"""

labels=['id', 'duration', 'protocol_type', 'service', 'flag',
       'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent',
       'hot', 'num_failed_logins', 'logged_in', 'num_compromised',
       'root_shell', 'su_attempted', 'num_root', 'num_file_creations',
       'num_shells', 'num_access_files', 'is_host_login',
       'is_guest_login', 'count', 'srv_count', 'serror_rate',
       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',
       'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate',
       'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate',
       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',
       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',
       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',
       'dst_host_srv_rerror_rate', 'class']
import seaborn as sns
plt.figure(figsize=(30,30))
cor = train_df.corr()
plt.figure(figsize = (50,40))
sns.heatmap(cor, annot=True, cmap=plt.cm.CMRmap_r,xticklabels=labels,yticklabels=labels)
plt.show()

cor_matrix = train_df.corr().abs()
upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(np.bool))
to_drop = [column for column in upper_tri.columns if any(upper_tri[column] >= 0.9)]
to_drop

test_df.drop(['num_root',
           'srv_serror_rate',
           'srv_rerror_rate',
           'dst_host_serror_rate',
           'dst_host_srv_serror_rate',
           'dst_host_rerror_rate',
           'dst_host_srv_rerror_rate'], axis=1,inplace= True)
train_df.drop(['num_root',
           'srv_serror_rate',
           'srv_rerror_rate',
           'dst_host_serror_rate',
           'dst_host_srv_serror_rate',
           'dst_host_rerror_rate',
           'dst_host_srv_rerror_rate'], axis=1,inplace= True) ## dropped because of highly correlated features

## the unique columns from service are = ['harvest', 'http_2784', 'red_i', 'http_8001', 'urh_i', 'aol']

train_df.drop(train_df.index[train_df['service'] == 'http_2784'], inplace = True)
train_df.drop(train_df.index[train_df['service'] == 'red_i'], inplace = True)
train_df.drop(train_df.index[train_df['service'] == 'http_8001'], inplace = True)
train_df.drop(train_df.index[train_df['service'] == 'urh_i'], inplace = True)
train_df.drop(train_df.index[train_df['service'] == 'aol'], inplace = True)
train_df.drop(train_df.index[train_df['service'] == 'harvest'], inplace = True)

"""Mapping attacks"""

train_df.attack.unique()

train_df['is_attack']=train_df['attack'].map(lambda a : 0 if a == 'normal' else 1)
test_df['is_attack']=test_df['attack'].map(lambda a : 0 if a == 'normal' else 1)

train_df.replace(to_replace =['apache2', 'back', 'land', 'mailbomb', 'neptune', 'pod', 'processtable', 'smurf', 'teardrop', 'udpstorm', 'worm'], 
                            value ="dos",inplace=True)

train_df.replace(to_replace =['ftp_write', 'guess_passwd', 'httptunnel', 'phf', 'imap', 'multihop', 'named', 'sendmail', 'snmpgetattack', 'snmpguess', 'spy', 'warezclient', 'warezmaster', 'xlock', 'xsnoop'], 
                            value ="r2l",inplace=True)

train_df.replace(to_replace =['ipsweep', 'portsweep', 'mscan', 'nmap', 'saint', 'satan'], 
                            value ="probe",inplace=True)

train_df.replace(to_replace =['buffer_overflow', 'loadmodule', 'perl', 'ps', 'sqlattack', 'rootkit', 'xterm'], 
                            value ="u2r",inplace=True)

test_df.replace(to_replace =['apache2', 'back', 'land', 'mailbomb', 'neptune', 'pod', 'processtable', 'smurf', 'teardrop', 'udpstorm', 'worm'
], 
                            value ="dos",inplace=True)

test_df.replace(to_replace =['ftp_write', 'guess_passwd', 'httptunnel', 'phf', 'imap', 'multihop', 'named', 'sendmail', 'snmpgetattack', 'snmpguess', 'spy', 'warezclient', 'warezmaster', 'xlock', 'xsnoop'], 
                            value ="r2l",inplace=True)

test_df.replace(to_replace =['ipsweep', 'portsweep', 'mscan', 'nmap', 'saint', 'satan'], 
                            value ="probe",inplace=True)

test_df.replace(to_replace =['buffer_overflow', 'loadmodule', 'perl', 'ps', 'sqlattack', 'rootkit', 'xterm'], 
                            value ="u2r",inplace=True)

train_df

apriori_df=pd.concat([train_df,test_df]).drop_duplicates().reset_index(drop=True)

apriori_df = apriori_df[['protocol_type', 'service', 'flag','attack']].copy()
apriori_df

di = {"normal" : 0,"dos" :1, "probe" :2, "r2l" :3 ,"u2r" :4} ## dictionary
train_df["attack"].replace(di, inplace=True)
test_df["attack"].replace(di, inplace=True)

train_df.attack.unique()

"""Checking the impact of each independent feature on Y"""

(train_df.corrwith(train_df["attack"]).sort_values(ascending=False))

test_df.drop(['hot',
           'wrong_fragment',
           'is_guest_login',
           'num_failed_logins',
           'src_bytes',
           'srv_diff_host_rate',
           'dst_bytes','root_shell','num_shells','urgent','land','is_host_login','num_compromised','num_file_creations','su_attempted','num_access_files','srv_count'], axis=1,inplace= True)
train_df.drop(['hot',
           'wrong_fragment',
           'is_guest_login',
           'num_failed_logins',
           'src_bytes',
           'srv_diff_host_rate',
           'dst_bytes','root_shell','num_shells','urgent','land','is_host_login','num_compromised','num_file_creations','su_attempted','num_access_files','srv_count'], axis=1,inplace= True)

"""Encoding"""

protocol_type=pd.get_dummies(train_df.protocol_type)
merged=pd.concat([train_df,protocol_type],axis='columns')
train_df=merged.drop(['protocol_type','icmp'],axis=1)

flag=pd.get_dummies(train_df.flag)
merged=pd.concat([train_df,flag],axis='columns')
train_df=merged.drop(['flag','SF'],axis=1)

service=pd.get_dummies(train_df.service)
merged=pd.concat([train_df,service],axis='columns')
train_df=merged.drop(['service','other'],axis=1)


protocol_type=pd.get_dummies(test_df.protocol_type)
merged=pd.concat([test_df,protocol_type],axis='columns')
test_df=merged.drop(['protocol_type','icmp'],axis=1)

flag=pd.get_dummies(test_df.flag)
merged=pd.concat([test_df,flag],axis='columns')
test_df=merged.drop(['flag','SF'],axis=1)

service=pd.get_dummies(test_df.service)
merged=pd.concat([test_df,service],axis='columns')
test_df=merged.drop(['service','other'],axis=1)

col = train_df.pop('attack')
train_df.insert(90,'attack',col,allow_duplicates=False)
col = test_df.pop('attack')
test_df.insert(90,'attack',col,allow_duplicates=False)

x_train=train_df.iloc[:,:-1].values
y_train=train_df.iloc[:,-1].values
x_test=test_df.iloc[:,:-1].values
y_test=test_df.iloc[:,-1].values

"""#Random Forest"""

#RANDOM FOREST
from sklearn.ensemble import RandomForestClassifier
model_RF = RandomForestClassifier(n_estimators = 10, random_state = 42)

# Train the model on training data
model_RF.fit(x_train, y_train)

#Test prediction on testing data. 
prediction_test_RF = model_RF.predict(x_test)

#ACCURACY METRICS
print("********* METRICS FOR IMBALANCED DATA *********")
#Let us check the accuracy on test data
from sklearn import metrics
print ("Accuracy = ", metrics.accuracy_score(y_test, prediction_test_RF))

#Wow!!! We got 91% accuracy
#print(np.unique(prediction_test_RF))
(unique, counts) = np.unique(prediction_test_RF, return_counts=True)
print(unique, counts)

#Confusion Matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, prediction_test_RF)
print(cm)

#Print individual accuracy values for each class, based on the confusion matrix
print("Pixel 0 accuracy = ", cm[0,0] / (cm[0,0]+cm[1,0]+cm[2,0]+cm[3,0]+cm[4,0]))
print("Pixel 1 accuracy = ",   cm[1,1] / (cm[0,1]+cm[1,1]+cm[2,1]+cm[3,1]+cm[4,1]))
print("Pixel 2 accuracy = ",   cm[2,2] / (cm[0,2]+cm[1,2]+cm[2,2]+cm[3,2]+cm[4,2]))
print("Pixel 3 accuracy = ",   cm[3,3] / (cm[0,3]+cm[1,3]+cm[2,3]+cm[3,3]+cm[4,3]))
print("Pixel 4 accuracy = ",   cm[4,4] / (cm[0,4]+cm[1,4]+cm[2,4]+cm[3,4]+cm[4,4]))







"""# Technique 2 Up-sample minority class

"""

from sklearn.utils import resample
print(train_df['attack'].value_counts())

#Separate majority and minority classes
df_important = train_df[train_df['attack'] == 2]
df_majority_1 = train_df[train_df['attack']== 1]
df_majority_0 = train_df[train_df['attack']== 0]
df_minority_3 = train_df[train_df['attack'] == 3]
df_minority_4 = train_df[train_df['attack'] == 4]

# Upsample minority class and other classes separately
# If not, random samples from combined classes will be duplicated and we run into
#same issue as before, undersampled remians undersampled.
df_minority_upsampled_3 = resample(df_minority_3, 
                                 replace=True,     # sample with replacement
                                 n_samples=66000,    # to match average class
                                 random_state=42) # reproducible results
 
df_minority_upsampled_4 = resample(df_minority_4, 
                                 replace=True,     # sample with replacement
                                 n_samples=66000,    # to match average class
                                 random_state=42) # reproducible results

df_majority_upsampled_1 = resample(df_majority_1, 
                                 replace=True,     # sample with replacement
                                 n_samples=66000,    # to match average class
                                 random_state=42) # reproducible results

df_important_upsampled = resample(df_important, 
                                 replace=True,     # sample with replacement
                                 n_samples=66000,    # to match average class
                                 random_state=42) # reproducible results

df_upsampled = pd.concat([df_minority_upsampled_3, df_important_upsampled,
                          df_minority_upsampled_4, df_majority_0,
                          df_majority_upsampled_1])
print(df_upsampled['attack'].value_counts())

Y_upsampled = df_upsampled["attack"].values

#Define the independent variables
X_upsampled = df_upsampled.drop(labels = ["attack"], axis=1)

#Train again with new upsamples data
model_RF_upsampled = RandomForestClassifier(n_estimators = 10, random_state = 42)

# Train the model on training data
model_RF_upsampled.fit(X_upsampled, Y_upsampled)
prediction_test_RF_upsampled = model_RF_upsampled.predict(x_test)

print("********* METRICS FOR BALANCED DATA USING UPSAMPLING *********")

print ("Accuracy = ", metrics.accuracy_score(y_test, prediction_test_RF_upsampled))

cm_upsampled = confusion_matrix(y_test, prediction_test_RF_upsampled)
print(cm_upsampled)

print("Pixel 0 accuracy = ", cm_upsampled[0,0] / (cm_upsampled[0,0]+cm_upsampled[1,0]+cm_upsampled[2,0]+cm_upsampled[3,0]+cm_upsampled[4,0]))
print("Pixel 1 accuracy = ",  cm_upsampled[1,1] / (cm_upsampled[0,1]+cm_upsampled[1,1]+cm_upsampled[2,1]+cm_upsampled[3,1]+cm_upsampled[4,1]))
print("Pixel 2 accuracy = ",  cm_upsampled[2,2] / (cm_upsampled[0,2]+cm_upsampled[1,2]+cm_upsampled[2,2]+cm_upsampled[3,2]+cm_upsampled[4,2]))
print("Pixel 3 accuracy = ",  cm_upsampled[3,3] / (cm_upsampled[0,3]+cm_upsampled[1,3]+cm_upsampled[2,3]+cm_upsampled[3,3]+cm_upsampled[4,3]))
print("Pixel 4 accuracy = ",  cm_upsampled[4,4] / (cm_upsampled[0,4]+cm_upsampled[1,4]+cm_upsampled[2,4]+cm_upsampled[3,4]+cm_upsampled[4,4]))



"""# SMOTE"""

pip install imblearn

from imblearn.over_sampling import SMOTE, ADASYN

X_smote, Y_smote = SMOTE().fit_resample(x_train, y_train)  #Beware, this takes some time based on the dataset size
#X_adasyn, Y_adasyn = ADASYN().fit_resample(x_train, y_train)

(unique, counts) = np.unique(y_train, return_counts=True)
print("Original data: ", unique, counts)
(unique2, counts2) = np.unique(Y_smote, return_counts=True)
print("After SMOTE: ", unique2, counts2)
#(unique3, counts3) = np.unique(Y_adasyn, return_counts=True)
#print("After ADASYN: ", unique3, counts3)

model_SMOTE = RandomForestClassifier(n_estimators = 10, random_state = 42)
model_SMOTE.fit(x_train, y_train)

prediction_test_smote = model_SMOTE.predict(x_test)

print ("Accuracy = ", metrics.accuracy_score(y_test, prediction_test_smote))

